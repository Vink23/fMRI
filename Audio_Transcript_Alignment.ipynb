{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN6lw0w+Wf+R7GWLcyoy/io"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN48-tPiXrtR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install -qq -y ffmpeg"
      ],
      "metadata": {
        "id": "RCsZchZbYAKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/m-bain/whisperx.git\n",
        "!pip install -q faster-whisper"
      ],
      "metadata": {
        "id": "uO26Y6ibYH7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisperx\n",
        "import torch\n",
        "import gc\n",
        "import traceback\n",
        "from google.colab import files, drive\n",
        "import os\n",
        "import shutil\n"
      ],
      "metadata": {
        "id": "3hIS6Sr7YL2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_code = \"en\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "compute_type = \"int8\" if device == \"cpu\" else \"float16\""
      ],
      "metadata": {
        "id": "852HQr5cC_af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dir = \"/content/drive/MyDrive/fMRI/stimuli\"\n",
        "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]"
      ],
      "metadata": {
        "id": "GXRM-JgyCai_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_a, metadata = whisperx.load_align_model(language_code=language_code, device=device)"
      ],
      "metadata": {
        "id": "pDk4VeTTEa1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in audio_files:\n",
        "    audio_file = os.path.join(audio_dir, file)\n",
        "    transcript_file = os.path.join(audio_dir, file.replace(\".wav\", \"_transcript.txt\"))\n",
        "    output_tsv_file = os.path.join(audio_dir, file.replace(\".wav\", \"_alignment_output.tsv\"))\n",
        "\n",
        "    print(f\"Loading audio from: {audio_file}\")\n",
        "    print(f\"Loading transcript from: {transcript_file}\")\n",
        "\n",
        "\n",
        "    try:\n",
        "\n",
        "      audio = whisperx.load_audio(audio_file)\n",
        "\n",
        "      audio_duration = audio.shape[0] / 16000.0\n",
        "\n",
        "      with open(transcript_file, 'r', encoding='utf-8') as f:\n",
        "          transcript_text = f.read()\n",
        "\n",
        "\n",
        "    # process the transcript\n",
        "      result_transcribe = {\n",
        "          \"segments\": [{\n",
        "              \"text\": transcript_text,\n",
        "              \"start\": 0,\n",
        "              \"end\": audio_duration\n",
        "         }]\n",
        "      }\n",
        "\n",
        "      # Alignment\n",
        "      print(\"Aligning transcription...\")\n",
        "      result_aligned = whisperx.align(\n",
        "          result_transcribe[\"segments\"],\n",
        "          model_a,\n",
        "          metadata,\n",
        "          audio,\n",
        "          device,\n",
        "          return_char_alignments=False\n",
        "     )\n",
        "\n",
        "      # Get word segments and confirm alignment\n",
        "      word_segments = result_aligned.get(\"word_segments\", [])\n",
        "      if not word_segments:\n",
        "          print(\"Alignment failed: No word segments found.\")\n",
        "          print(\"Full aligned result:\", result_aligned)\n",
        "      else:\n",
        "         # Write/format and save to .tsv\n",
        "          print(f\"\\n--- Alignment Complete ---\")\n",
        "          print(f\"Saving word-level timestamps to {output_tsv_file}...\")\n",
        "\n",
        "          with open(output_tsv_file, 'w', encoding='utf-8') as f:\n",
        "\n",
        "              f.write(\"word\\tstart\\tend\\n\")\n",
        "\n",
        "              for segment in word_segments:\n",
        "                  word = segment.get('word', 'N/A').strip()\n",
        "                  start_time = segment.get('start', 'N/A')\n",
        "                  end_time = segment.get('end', 'N/A')\n",
        "\n",
        "                  if isinstance(start_time, float) and isinstance(end_time, float):\n",
        "                      f.write(f\"{word}\\t{start_time:.3f}\\t{end_time:.3f}\\n\")\n",
        "                  else:\n",
        "                      # Handle cases where timestamps might be missing\n",
        "                      f.write(f\"{word}\\t{start_time}\\t{end_time}\\n\")\n",
        "\n",
        "          print(\"Successfully saved the output.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred: {e}\")\n",
        "        print(\"\\n--- Traceback ---\")\n",
        "        traceback.print_exc()\n",
        "        print(\"-----------------\")\n",
        "\n",
        "    finally:\n",
        "        print(\"\\nCleaning up memory...\")\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "C-5EZ9egCkB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dir = \"/content/drive/MyDrive/fMRI/stimuli\"\n",
        "\n",
        "audio_recording_dir = os.path.join(audio_dir, \"original_audio_recordings\")\n",
        "transcript_dir = os.path.join(audio_dir, \"transcripts\")\n",
        "tsv_dir = os.path.join(audio_dir, \"force_aligned_perword_timestamp\")\n",
        "\n",
        "os.makedirs(audio_recording_dir, exist_ok=True)\n",
        "os.makedirs(transcript_dir, exist_ok=True)\n",
        "os.makedirs(tsv_dir, exist_ok=True)\n",
        "\n",
        "for file in os.listdir(audio_dir):\n",
        "    file_path = os.path.join(audio_dir, file)\n",
        "    if os.path.isfile(file_path):\n",
        "        if file.endswith(\".wav\"):\n",
        "            shutil.move(file_path, os.path.join(audio_recording_dir, file))\n",
        "        elif file.endswith(\".txt\"):\n",
        "            shutil.move(file_path, os.path.join(transcript_dir, file))\n",
        "        elif file.endswith(\".tsv\"):\n",
        "            shutil.move(file_path, os.path.join(tsv_dir, file))"
      ],
      "metadata": {
        "id": "NwvKVKE0LPk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_files_in_folder(folder_path):\n",
        "    return len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "\n",
        "num_audio_files = count_files_in_folder(audio_dir)\n",
        "num_transcript_files = count_files_in_folder(transcript_dir)\n",
        "num_tsv_files = count_files_in_folder(tsv_dir)\n",
        "\n",
        "\n",
        "print(f\"Number of .wav files in 'original_audio_recordings': {num_audio_files}\")\n",
        "print(f\"Number of .txt files in 'transcripts': {num_transcript_files}\")\n",
        "print(f\"Number of .tsv files in 'force_aligned_perword_timestamp': {num_tsv_files}\")\n"
      ],
      "metadata": {
        "id": "wEOMB7VuShUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_files = {os.path.splitext(f.strip())[0].lower() for f in os.listdir(transcript_dir) if f.endswith(\".txt\")}\n",
        "tsv_files = {os.path.splitext(f.strip())[0].lower() for f in os.listdir(tsv_dir) if f.endswith(\".tsv\")}\n",
        "\n",
        "\n",
        "print(f\"Transcript files (count {len(transcript_files)}): {sorted(transcript_files)}\")\n",
        "print(f\"TSV files (count {len(tsv_files)}): {sorted(tsv_files)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RTFlLbseS3k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tlist = []\n",
        "tslist = []\n",
        "for file in transcript_files:\n",
        "  tlist.append(file[:-11])\n",
        "for tfile in tsv_files:\n",
        "  tslist.append(file[:-17])"
      ],
      "metadata": {
        "id": "8pjAdungUHT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}